{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing around with an alternate, Python AST-based embedding of Halide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exploratory _sketching_, and not internally consistent — it is meant to\n",
    "be toying with different possible syntax ideas in different places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# A first cut\n",
    "\n",
    "Assume the existence of some core Halide decorators and types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nop(*args, **kwargs): pass\n",
    "func = pure = update = pipe = var = _nop\n",
    "Buffer = UInt = Int = Float = _nop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Funcs\n",
    "Raw and simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Buffer(UInt(16), 2)\n",
    "\n",
    "@func\n",
    "def blur_x(x, y):\n",
    "    return (inp(x-1, y) + inp(x, y) + inp(x+1, y)) / 3\n",
    "\n",
    "@func\n",
    "def blur_y(x, y):\n",
    "    return (blur_x(x-1, y) + blur_x(x, y) + blur_x(x+1, y)) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure funcs are actually just sensible (if slow) Python.\n",
    "\n",
    "Is it possible to interpret these with a vectorized semantics where they also\n",
    "take *intervals* for the dimensions, and return arrays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantics\n",
    "I quickly found myself drawn into the idea that this should also be able to\n",
    "have a simple semantics defined in terms of regular Python, without too many\n",
    "rewrites implied by the decorators, if you allow `Var` arguments to take\n",
    "vectors or ranges as well as scalar values. I was imagining that a simple\n",
    "interpreter based on pushing through NumPy arrays would just work with fairly\n",
    "modest translation of the AST that Python-fluent programmers could easily learn\n",
    "and understand. I'm not sure whether this is actually a good idea to prioritize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update stages\n",
    "What about update stages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func # or @MultiStageFunc?\n",
    "def multi_stage(x, y):\n",
    "    @pure # or @Init or @func\n",
    "    def init(x,y):\n",
    "        return 0\n",
    "    \n",
    "    # This initialization can't be very general\n",
    "    res = init(x,y)\n",
    "\n",
    "    @update\n",
    "    def upd():\n",
    "        for i in seq(-1,1):\n",
    "            for j in seq(-1,1):\n",
    "                res += inp(x+i, y+j)\n",
    "    \n",
    "    return res # ugly/verbose, but clear/explicit?\n",
    "    # What about applying the update(s)?\n",
    "    #   like `return upd(res)`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems potentially confusing.\n",
    "\n",
    "- Do we close over the x,y of the parent?\n",
    "- Do the vectorized semantics properly carry over?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### What about a histogram & scan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func\n",
    "def hist(i):\n",
    "    @pure\n",
    "    def init(i):\n",
    "        return 0\n",
    "    \n",
    "    res = init(i)\n",
    "    \n",
    "    # Realizing: vectorized semantics will require a bounds inference pass/step.\n",
    "    # The update clearly can't work with just a scalar `res`.\n",
    "    # Alternate:\n",
    "    res = init([min(0, i), max(255, i)])\n",
    "    \n",
    "    @update\n",
    "    def upd():\n",
    "        for y in seq(inp.height()):\n",
    "            for x in seq(inp.width()):\n",
    "                # Should this be (call) or [array index]?\n",
    "                res[inp(x,y)] += 1\n",
    "                # It *has* to be array index, because Python won't parse an\n",
    "                # assign to a call!\n",
    "\n",
    "    # If the initialized interval is larger than i, then this should be sliced\n",
    "    return res(i)\n",
    "\n",
    "@func\n",
    "def cdf(i):\n",
    "    @pure \n",
    "    def init(i):\n",
    "        return 0\n",
    "    # This dummy init is getting tiresome!\n",
    "    \n",
    "    res = init(i)\n",
    "    \n",
    "    @update\n",
    "    def upd():\n",
    "        for i in seq(0, 255):\n",
    "            res[i] = res[i-1]+hist(i)\n",
    "\n",
    "@func\n",
    "def normalized(x,y):\n",
    "    return cdf(inp(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounds inference with vectorized semantics would *mostly* just propagate bounds\n",
    "back to start, then pull forward. Main issue are update stages where the RDom\n",
    "also influences the bounds.\n",
    "\n",
    "Maybe this is manageable with some non-crazy rewrites in the decorator? What\n",
    "would a bounds protocol compatible version of the histogram or cdf look like?\n",
    "=> It would have the computed interval set on the init, and the result sliced\n",
    "out to return.\n",
    "\n",
    "For the vectorized semantics to work without some vector calls in the return\n",
    "statement, this would probably have to be rewritten in the decorator to\n",
    "implicitly allocate the return buffer over x,y, then populate and return that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func\n",
    "def test(x,y):\n",
    "    return 0 # would not generate a vector, even if x,y were vectors\n",
    "\n",
    "def test_transformed(x, y):\n",
    "    res = alloc(x,y)\n",
    "    res[x,y] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] **TODO:** Are generators just functions which locally define and return Funcs?\n",
    "- [ ] **TODO:** Try porting all of an app to see how it looks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternates\n",
    "\n",
    "These are parameterized over inputs. Properly general, but verbose, and doesn't\n",
    "correspond to actual Halide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_x(x : Var, y : Var, inp : Func):\n",
    "    return (inp(x-1, y) + inp(x, y) + inp(x+1, y))/3\n",
    "\n",
    "def blur_y(x : Var, y : Var, bx : Func):\n",
    "    return (bx(x, y-1) + bx(x, y) + bx(x, y+1))/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] **TODO:** What about return types? Consider setting / checking them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision 1\n",
    "## Stripped down update stage syntax\n",
    "\n",
    "  - If it's a multi-stage func, we don't need decorators inside. It should all\n",
    "    be defs, with the first a pure init, and the rest updates taking a result\n",
    "    buffer.\n",
    "\n",
    "  - Inner stage definitions DO NOT take Var arguments. They have to close over\n",
    "    the vars of the parent. If the since those are the only dims which are\n",
    "    actually available. Paired with a simple syntactic rule that a multi-stage\n",
    "    func can ONLY contain a list of `def`s and no other statements, this should\n",
    "    syntactically (roughly) enforce a clear model of what is semantically\n",
    "    possible.\n",
    "\n",
    "  - Maybe the semantics aren't that bad? They hopefully just correspond to the\n",
    "    decorator implying that you add a final line to return the result of\n",
    "    applying each of the stages in order:\n",
    "    \n",
    "      ```\n",
    "      return upd2(upd1(init())) # still implicitly closed over x,y\n",
    "      ```\n",
    "    \n",
    "    For bounds inference of RDoms to work, this probably also requires that\n",
    "    init() first be extended to take explicit bounds, which are also computed\n",
    "    and inserted from all the update steps.\n",
    "    \n",
    "  - Inits to 0 can be omitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func\n",
    "def hist(i):\n",
    "    def init():\n",
    "        return 0\n",
    "\n",
    "    def upd(res):\n",
    "        for y in seq(inp.height()):\n",
    "            for x in seq(inp.width()):\n",
    "                # brackets for the result update, implying that it's a mutable\n",
    "                # array at this point?\n",
    "                res[inp(x,y)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Simple blur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "@func\n",
    "def blur(x, y):\n",
    "    def init():\n",
    "        return 0\n",
    "    \n",
    "    def upd(res):\n",
    "        for i in seq(-1,1):\n",
    "            for j in seq(-1,1):\n",
    "                res[x,y] += inp(x+i, y+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Should res have to be indexed in this case? Is there a difference between\n",
    "  that, and allowing a scalar res (or one that's pure along some dimensions but\n",
    "  not others)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "A few tweaked alternatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func\n",
    "def blur(x, y):\n",
    "    # Consider: Init expr as default res argument to first update?\n",
    "    # def upd(res = 0), or:\n",
    "    def upd(res = zeros(x,y)):\n",
    "        for i in seq(-1,1):\n",
    "            for j in seq(-1,1):\n",
    "                res[x,y] += inp(x+i, y+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "@func\n",
    "def blur(x, y):\n",
    "    # Consider: default init to 0 is optional?\n",
    "    \n",
    "    # Consider: make update buffer argument optional, allow recursive use of\n",
    "    #           func name instead?\n",
    "    #\n",
    "    # I actually think this is just less clear. The idea of having a mutable\n",
    "    # result buffer for updates makes the model, and how these are different\n",
    "    # from pure stages, seem significantly more obvious.\n",
    "    def upd():\n",
    "        for i in seq(-1,1):\n",
    "            for j in seq(-1,1):\n",
    "                blur[x,y] += inp(x+i, y+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think that was effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This is starting to feel decent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func\n",
    "def iir_blur(x, y):\n",
    "    def init():\n",
    "        return undef(float)\n",
    "    \n",
    "    def init_top(buf):\n",
    "        buf[x, 0] = inp(x, 0)\n",
    "    \n",
    "    def down_columns(res):\n",
    "        for ry in seq(1, height):\n",
    "            res[x, ry] = (1 - alpha) * res(x, ry - 1) + alpha * input(x, ry)\n",
    "    \n",
    "    def up_columns(res):\n",
    "        for ry in seq(1, height):\n",
    "            flip_ry = height - y - 1 # this just becomes an Expr\n",
    "            res[x, flip_ry] = (1 - alpha) * res[x, flip_ry + 1] \\\n",
    "                                  + alpha * res[x, flip_ry]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How will we represent schedules?\n",
    "My initial thought was that you'd be able to just reach in and grab update\n",
    "stages by field reference chaining, like `iir_blur.init_top`. But I realize\n",
    "this only addresses func/stage references, and doesn't cover how to name the\n",
    "Vars or RVars.\n",
    "\n",
    "A more explicit model would have you do like `blur.upd.i` or `blur_x.x`. (The\n",
    "`@func` decorator would always translate the function into an object that had\n",
    "these members populated.)\n",
    "\n",
    "Maybe the verbosity of the more explicit model of having vars associated with\n",
    "their function definition actually makes things clearer? It's often unclear to\n",
    "new users which `x` you're even referring to when you use a Var in a complex\n",
    "scheduling statement (especially one involving multiple Funcs like `compute_at`)\n",
    "\n",
    "An extreme other end would be to just let you use strings and match those with\n",
    "the names in the definitions: you'd use `'x'` instead of `blur_x.x`.\n",
    "\n",
    "Maybe we support both of these?  \n",
    "Is the more explicit form encouraged?  \n",
    "Are strings automatically translated into the more explicit form?\n",
    "\n",
    "One notable thing with the explicit form: `compute_at` and `store_at` would\n",
    "need only a single argument, not two, as `f.compute_at(g.x)` is unambiguous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nesting\n",
    "One thought: this syntax seems to naturally lend itself to nesting pipelines\n",
    "within Funcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func\n",
    "def parent(x,y):\n",
    "    @func\n",
    "    def child1(x,y):\n",
    "        return x+y\n",
    "    \n",
    "    @func\n",
    "    def child2(x,y):\n",
    "        return child1(x-1,y) + child1(x,y)\n",
    "    \n",
    "    return child2(x*2,y*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variant feels awkward, as it doesn't really make the sub-pipeline a\n",
    "separate thing, which could be applied multiple times. This really seems to\n",
    "require [lambda abstraction](#Lambda-Abstraction) of the child pipeline to make\n",
    "sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Abstraction\n",
    "...would amount to allowing Func definitions and calls to take params other\n",
    "than just Vars.\n",
    "\n",
    "The types of params would be the same as those allowed in Generators.  \n",
    "Would they also have Input and Output desigations, and default values?\n",
    "\n",
    "How do you abstract over multi-output `Pipeline`s?\n",
    "\n",
    "This is also a question for the core Halide IR and language, as much as it is\n",
    "for this new embedding. But this embedding could presumably add lambda\n",
    "abstraction, with basic restrictions (no recursion), and entirely de-sugar\n",
    "applications of lambdas into a flattened program (or maybe a C++ Generator?) in\n",
    "the front-end for now.\n",
    "\n",
    "***\n",
    "\n",
    "There is a strong correspondence between lambda abstraction and Generators. A\n",
    "Generator (or the subset which is maps params to a pipeline) really is our\n",
    "lambda.\n",
    "\n",
    "If we could just make the syntax way more obvious and concise, is this all we\n",
    "need? Perhaps a simple `@pipeline` _is_ the unit of lambda abstraction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where do the dimensions go?\n",
    "# What about multiple outputs, with different dimensionality?\n",
    "# Multiple outputs can just be a tuple of @funcs returned from the @pipe.\n",
    "@pipe\n",
    "def my_first_generator(offset : UInt(8), input : Buffer(UInt(8), 2)):\n",
    "    @func\n",
    "    def brighter(x,y):\n",
    "        return input(x,y) + offset\n",
    "    \n",
    "    # Schedule here? Or def schedule()?\n",
    "    \n",
    "    return brighter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we define a pyramid constructor that re-uses the same subroutine logic at\n",
    "every level as a nested pair of pipelines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Pending Ideas & Questions\n",
    "- [ ] With the nesting of function definitions to create multi-stage Funcs and\n",
    "  Pipelines/generators, should we consider a **class**-based top-level\n",
    "  structure, instead of a **function**-based one?\n",
    "    - What are the syntacting objects to which decorators can be applied? Any\n",
    "      besides `def` and `class`?\n",
    "- [ ] What about inline reduction helpers?\n",
    "    - How do they carry over?\n",
    "        - Just pass through to the C++ syntax stupidly? Is that feasible?\n",
    "        - What about if we try to dump out as serialized IR — they don't exist\n",
    "          then?\n",
    "    - Could you implement them nicely in this syntax?\n",
    "        - Can you have a scalar intermediate that's just used within the loops\n",
    "          of an update, and then assigned to `res[x,y]`\n",
    "- [ ] Are there loops other than `seq`? Can there be a `par` loop, and what\n",
    "  would it mean?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
